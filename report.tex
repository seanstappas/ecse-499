\documentclass[titlepage,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{indentfirst}
\usepackage[per-mode=symbol]{siunitx}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath}
\usepackage{array}
\usepackage[hidelinks]{hyperref}
\usepackage[format=plain,font=it]{caption}
\usepackage{subcaption}
\usepackage{standalone}
\usepackage[nottoc]{tocbibind}
\usepackage{scrextend}
\usepackage[margin=1in]{geometry}
\usepackage[super]{nth}
\usepackage{todonotes}
\usepackage[noabbrev,capitalize,nameinlink]{cleveref}
\usepackage{mathtools}
\usepackage{pdflscape}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\def\equationautorefname~#1\null{%
  Equation~(#1)\null
}

\def\sectionautorefname~#1\null{%
  Section~#1\null
}

\def\subsectionautorefname~#1\null{%
  Subsection~#1\null
}

\def\arraystretch{1.3}%  1 is the default, change whatever you need

% Custom commands
\newcommand{\ar}[1]{\autoref{#1}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\specialcell}[2][c]{%
	\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

\title
{
	\uppercase{Prometheus AI} \\
	\large Phase 2
}
\author % (optional, for multiple authors)
{
	Sean Stappas \\ 
	260639512 \\
	\\ 
	ECSE-499: Honours Thesis II \\
	\\
	\small Supervised by: Prof. Joseph Vybihal
}
\date{December \nth{7}, 2017}

\begin{document}
	
\sloppy

\maketitle

\section*{Abstract}
% The abstract is an executive summary of your project/thesis. It should provide an overview of your project/thesis by addressing the following questions. a. What is the motivation for the project/thesis? b. What are the goals of the project/thesis? c. What was achieved this semester? d. What methods were used to make those achievements? The abstract should be between 200 and 250 words long.
Prometheus AI is a model of the human brain aimed at controlling multiple robots to achieve some goal. Possible application areas include environments hazardous for humans, such as in the aftermath of a nuclear power disaster or in outer space. The model consists of four layers: the Neural Network (NN), the Knowledge Node Network (KNN), the Expert System (ES) and the Meta Reasoner (META). The NN classifies the signals coming from the robots' sensors and sends formatted tags to the KNN. The KNN represents memory and can initiate cascaded activation of memories in the form of tags, which are passed on to the ES. The ES is a simple logic reasoner and provides recommendations for actions to the META. The META represents high-level thinking and makes an intelligent decision to either accept the recommendations from the ES or to initiate a new thinking cycle in the KNN. The tasks for this thesis were to implement the KNN and ES layers in Java and to supervise work done by undergraduate students on Prometheus. This was achieved using design criteria such as efficiency, readability and testability. Continuous integration tests were created on GitHub\footnote{The GitHub repository can be found here:\\ \url{https://github.com/seanstappas/prometheus-ai/}\\} with TestNG and TravisCI\footnote{The Travis CI builds can be found here:\\ \url{https://travis-ci.com/seanstappas/prometheus-ai}\\} and extensive documentation was written in Javadoc\footnote{The Javadoc can be found here:\\ \url{http://seanstappas.me/prometheus-ai/}}.

\section*{Acknowledgments}
% If applicable, you may acknowledge people here who contributed to the project in some way but are not listed on the title page. (For example, if you received advice, data, or supervision from graduate students or others.)
Under my supervision, several undergraduate students worked on the Prometheus layers in Prof. Vybihal's lab. Over the summer, Isaac Sultan and Si Yi Li made contributions to the ES and KNN layers, respectively. This semester, Mohammad Owais Kerney and Michael Ding showed interest in the NN and META layers, respectively.

\clearpage
\tableofcontents

\listoffigures
\listoftables
%\lstlistoflistings
\clearpage

\twocolumn

\section*{Abbreviations}
% List of abbreviations and/or notation used in the report.

The following abbreviations will be used throughout the report:

\begin{table}[!htb]
	\centering
	\caption{Abbreviations in Prometheus.}
	\begin{tabular}{r | l}
		\textbf{Abbreviation} & \textbf{Meaning} \\ \hline
		NN & Neural Network \\
		KNN & Knowledge Node Network \\
		KN & Knowledge Node \\
		ES & Expert System \\
		META & Meta Reasoner
	\end{tabular}
	\label{table:abbrevations}
\end{table}

\section{Introduction} \label{sec:intro}
% In this section you should introduce (at a high level) the overall theme of the project, and state clearly what are the goals you are trying to achieve.  This section should also clearly convey why this project is important, what is the potential impact (applications, etc).

Prometheus is an artificial intelligence system designed to control multiple robots to achieve some goal. All the thinking and decision-making is done by the system, which collects data from all the robots' sensors.

Applications for this type of system include robots in hazardous environments, such as in outer space (Mars, Moon, etc.), in nuclear plants after a disaster and in military zones.  The system could theoretically learn from this data in a given environment and apply its learning to new environments.

The architecture of Prometheus is loosely inspired from the structure of the human brain and is composed of the following four layers \cite{vybihal-model}: the Neural Network (NN), the Knowledge Node Network (KNN), the Expert System (ES) and the Meta Reasoner (META). A high-level diagram of the system can be seen in \autoref{model}.

\begin{figure*}[!htb]
	\includegraphics[width=\textwidth]{figures/ai_model.pdf}
	\caption[Prometheus AI model.]{Prometheus AI model. Blue represents Prometheus and red represents the robots.}
	\label{model}
\end{figure*}

The scope of this thesis is to implement the KNN and ES layers of Prometheus. Therefore, more detail will be given for these layers.

The theory needed to understand these four layers will be given in \autoref{sec:background}. The assigned task will then be described in \autoref{sec:problem}. Design criteria will be discussed in \autoref{sec:design}. The description of the work done can be found in \autoref{sec:implementation}. The results and tests will be discussed in \autoref{sec:results}. Finally, the possible future impact of this project on society and the environment will be explored in \autoref{sec:impact}.

\section{Background} \label{sec:background}
% In this section you should summarize the theory and background that you had to learn, and that you believe are necessary for the reader to understand the rest of the report.
This section draws heavily from the background discussed in the previous report \cite{stappas}.

\subsection{Neural Network}

The NN layer consists of a network of neurons with a structure similar to neurons in the human brain. It is the interface between the robots' sensors and the rest of the AI system.

The robots in Prof. Vybihal's lab are equipped with two types of sensors: camera and ultrasonic. The ultrasonic sensor can measure distance between the robot and nearby objects and the camera can take images of what the robot is facing.
%The robots have a fixed front-facing camera. Each robot may have multiple fixed ultrasonic sensors pointing in different directions, or a single rotating ultrasonic sensor that sweeps the area in front of the robot. 

The NN gathers raw sensor data and will build an abstract view of the robot's surrounding environment. For each camera image, it will achieve two main goals:

\begin{enumerate}
	\item Classify objects observed in the image.
	\item Localize objects in the image.
\end{enumerate}

Ultimately, the classification and localization of objects will produce abstract informational tags, which will be passed on to the KNN. These tags can therefore be characteristics of objects in the world, such as distance. The tags can also have associated confidence values, which can be converted to belief within the KNN.

\subsection{Knowledge Node Network}

The KNN layer is the analog to memory in the human brain. It takes in the tags provided by the NN and outputs tags based on its knowledge. It consists of interconnected Knowledge Nodes (KNs), which are abstract structures representing memories and their connections to other memories. A simple model of a Knowledge Node (KN) can be seen in \ar{kn}.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/knowledge_node.pdf}
	\caption[High-level model of the Knowledge Node of the KNN.]
	{High-level model of the Knowledge Node (KN) of the KNN.}
	\label{kn}
\end{figure}

\subsubsection{Excitation and Firing}
KNs have an input tag representing some datum and output tags representing related data. When a KN is stimulated it becomes ``excited''. Tags in the KNN can become ``active'', potentially exciting the associated KN. We say that the associated KN ``fires'' if it is excited beyond a threshold. For example, if the NN observes a ball and provides that information to the KNN, then a ``ball'' tag may become active in the KNN. This would excite the KN with input tag ``ball''. If that KN fires, other tags related to that observation can become active. For example, tags representing ball characteristics such as ``round object'' may become active. This tag in turn may be connected to another KN, potentially causing more activation. More details about the structure of these tags will be provided in \cref{sec:background_expert_system}, where the Expert System will be discussed.

\subsubsection{Strength}
There is a strength value associated with every KN which represents how much weight an activation has and therefore how quickly that node will fire. Strength can be seen as the firing predisposition of neurons in the brain as a result of learning \cite{vybihal-knowledge}. Indeed, learning can increase the synaptic strength between neurons and cause early  firing of those neurons \cite{hebb}. For example, a person who has had a bad experience with spiders would fire their fear response upon seeing a spider more quickly than one without that fear.

\subsubsection{Belief}
Every KN can have a belief value associated with it, representing how certain the KNN is that the input tag is true. In this case, the belief value would be stored within the KN itself. These belief values can come from the NN, since a neural network can associate confidence values with its classifications of objects \cite{mitchell1997machine}. When initiating a think cycle, the belief values at each stage can be multiplied with each other to produce a new belief value, making the KNN less certain of a memory as it searches through its tree of KNs. This represents how belief changes when thinking. Indeed, some memories in the brain require a great deal of thinking to reach and, as such, can be less certain than other memories. This can lead to the recollection of false memories \cite{falsememories}.

Note that the activation of a KN and the belief value associated with it are two different concepts. Indeed, a KN may be fired even if the KNN knows that it is false. This can represent an agent ``lying'' to itself or repeating a thought process it knows to be false. This is known as ``self-deception'' in humans and it has been argued that this can be used for positive mental health \cite{taylor1989positive}. In the context of Prometheus, this may help the system achieve its desired goal.

\subsubsection{Search}
Searching in the KNN represents a tag activation routine. The KNN has four ways of searching: direct, forward, backward and lambda. Thinking in the KNN is a related concept to searching. When thinking, the KNN uses its currently active tags to activate further tags. In this way, thinking is a special case of searching, where the input tags of the search are the active tags in the KNN. The KNN has three ways of thinking: forward, backward and lambda. The version of searching or thinking to be done by the KNN is chosen by the META. 

Direct searching is a simple lookup of the desired tag and excitation of the associated KN. This is the simplest search in the KNN and can be seen in \cref{fig:direct_search}.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/direct_search.pdf}
	\caption{Direct searching in the KNN.}
	\label{fig:direct_search}
\end{figure}

Forward searching or thinking is depicted in \autoref{think_forwards}. Firing a KN can cause forward activation of more KNs, hence the ``forward'' naming. It repeatedly performs the same task as direct search on activated tags.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/forward_search.pdf}
	\caption{Forward searching or thinking in the KNN.}
	\label{think_forwards}
\end{figure}

Searching or thinking backward starts at the output tags of KNs and works backwards, as can seen in \autoref{think_backwards}. It checks the output tags of a KN and, if a certain ratio of them match the search input tags, the KN's input tag is activated. This ratio is known as the partial match ratio.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/backward_search.pdf}
	\caption{Backward searching or thinking in the KNN.}
	\label{think_backwards}
\end{figure}

The partial match ratio relates to the extent to which the KNN believes the tag associated with that node to be true. As a concrete example, if you observe an object that has four wheels, seats and a steering wheel, how confident are you that that object is a car? Realistically, humans will often classify what they observe with some uncertainty \cite{uncertainty} and this can be represented with backwards thinking. This type of thinking occurs constantly in the background in humans \cite{vybihal-knowledge}.

Lambda searching or thinking uses a combination of forward and backward. It can can be seen in \autoref{think_lambda}. It is called ``lambda'' because the shape of the thinking trajectory resembles a Greek uppercase lambda ($\Lambda$). It first looks at output tags of KNs and propagates activation backwards, similar to backward search. After a certain amount of nodes are fired, it will then start activating forwards, similar to forward search. An interesting question is how far backwards should lambda thinking go before starting to cascade forwards? This relates to how general one wants to explore before searching for a more specific value.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/lambda_search.pdf}
	\caption{Lambda searching or thinking in the KNN.}
	\label{think_lambda}
\end{figure}

Lambda thinking occurs in humans when using analogical reasoning to find a memory \cite{vybihal-lambda}. In essence, when a person wants to locate a memory that is not directly accessible, they will explore related memories, move their way ``backwards'' to similar concepts and think ``forwards'' to focus in on the desired memory. For example, if one is asked where they were in 2002 on a specific date, they most likely would not remember. If they explore related dates and events in their life, however, they may be able to narrow down their thoughts and extract that memory. In the context of the Prometheus system, lambda search will be attempted if all other searches fail (forward and backward).

All forms of searching or thinking can continue until there are no more tags to activate, which corresponds to natural quiescence. There can also be a fixed number of thinking cycles, which represents how much effort is being put into thinking. Indeed, in humans, thinking is done with varying degrees of effort \cite{thinking}. This number of thinking cycles also represents how deep the search will go into the KN graph and is therefore called the ``ply'' of the search.

\subsubsection{Aging}

Age represents how long it has been since a KN has been excited. After a KN has aged a certain amount of time, that node will be discarded, similarly to how old memories are discarded in the brain \cite{aging}. In backward search, ``young'' KNs (with a low age) are visited first. Here, there can also be an age threshold such that the KNN only searches through KNs below a certain age.

The result of all forms of searching or thinking is a collection of activated tags, which are passed on to the ES.

\subsection{Expert System} \label{sec:background_expert_system}

The ES layer is a basic logic reasoner. It is not aware of its current reality or any context. It takes in the tags provided by the KNN and interprets them as either facts, recommendations or rules.

\subsubsection{Facts}
Facts are simple calculus predicates showing that something is true. Their form can be seen in \cref{eq:fact}, where $P$ is the predicate name and each $A_i$ is an argument.

\begin{equation} \label{eq:fact}
	Fact \coloneqq P(A_1, \ldots, A_n)
\end{equation}

\cref{table:fact_predicates} shows some example facts with simple arguments and their meanings. Note that the arguments are relevant when matching with other facts.

\begin{table}[!htb]
	\centering
	\caption{Examples of facts in the ES.}
	\begin{tabular}{r | l}
		\textbf{Fact} & \textbf{Meaning} \\ \hline
		$P(x)$ & $x$ is true or active.\\
		$P(x = 1)$ & $x$ is equal to 1. \\
		$P(x \ != 1)$ & $x$ is not equal to 1. \\
		$P(x > 1)$ & $x$ is greater than 1. \\
		$P(x < 1)$ & $x$ is less than 1. \\
		$P(\&x)$ & $x$ can take any integer value. \\
		$P(*)$ & All arguments can take any value. \\
		$P(?)$ & One argument can take any value. \\
	\end{tabular}
	\label{table:fact_predicates}
\end{table}

As a concrete example, a fact argument can represent a certain measurement, e.g., $distance = 5$ representing a robot's distance from a wall as measured by one of its sensors.

\subsubsection{Recommendations}
Recommendations represent suggestions for actions to be taken by a robot. They take on the same predicate form as Facts, as shown in \cref{eq:recommendation}. The only difference is that it is customary to prefix the predicate name with a `@' character. For example, @Turn(left) is a recommendation for a robot to turn left, if it sees a wall directly in front of it and must avoid it, for example. These are recommendations and not commands because the META can decide whether or not to perform that action.

\begin{equation} \label{eq:recommendation}
	Recommendation \coloneqq @P(A_1, \ldots, A_n)
\end{equation}

\subsubsection{Rules}
Rules are many-to-many structures with facts as inputs and tags as outputs. This can be seen in \autoref{eq:rule}, where $m \geq 1$ and $n \geq 1$, i.e., there must be at least one input fact and one output tag. Each output tag can either be a fact or a recommendation. When all the input facts become active, the output tags become active and the rule itself is said to be active. In this way, a rule can represent a logical AND of all its input facts.

\begin{equation} \label{eq:rule}
	Rule \coloneqq Fact_1 \ldots Fact_m \rightarrow Tag_1 \ldots Tag_n
\end{equation}

\subsubsection{Thinking}
The runtime of the ES consists of the following general steps \cite{vybihal-expert}:

\begin{enumerate}
	\item Reset.
	\item Add facts and rules.
	\item Think.
	\item Send recommendations to META.
\end{enumerate}

The most important part of the previous process is the thinking stage, which represents the activation routine of the ES. This consists of first iterating through all the rules in the ES and checking if they are active by inspecting the lists of facts and recommendations. Rules may then become active and cause cascading activation of more rules. This can continue until there are no more rules to activate, which corresponds to natural quiescence. There can also be a fixed number of thinking cycles, which represents the effort put into thinking, similarly to the KNN. The recommendations activated as a result of thinking are passed on to the final layer, the META.

\subsection{Meta Reasoner}

The META layer represents high-level reasoning in the human brain. It is aware of its environment and context. It makes decisions based on what it believes to be right. It is paranoid and constantly checks whether the recommendations suggested by the ES make sense based on its expected view of the world. If it decides to make a decision, it sends a command to the actuators of the robots to decide how to move. If it is not happy with the recommendations from the ES, it may send a query back to the KNN to initiate another think cycle and generate new recommendations, as can be seen in \cref{model_labeled}.

\begin{figure*}[!htb]
	\includegraphics[width=\textwidth]{figures/ai_model_labeled.pdf}
	\caption{Prometheus AI model with labeled input and output.}
	\label{model_labeled}
\end{figure*}

\subsection{Summary}

With this full description of the Prometheus AI model, the system with labeled input and output can be seen in \autoref{model_labeled}.

\section{Problem}
\label{sec:problem}
% In this section you should describe the problem or system you are addressing in detail. Describe the project requirements and constraints.

The main task for this thesis is to construct the KNN and ES in Java. The requirement is that these layers should implement the functionality described in \autoref{sec:background}. Another important task is to supervise the work of other undergraduate students working on Prometheus and to put systems in place to ensure a certain standard for the code. The design criteria for both these tasks will be discussed in \autoref{sec:design} and their implementation will be discussed in \cref{sec:implementation}.

\section{Design}
\label{sec:design}
% In this section you must describe any design work that was already completed. Discuss any design decisions that have been made, and describe the process that was followed to make these decisions. Also discuss any results that have already been obtained this semester.

\subsection{Efficiency}
A very important consideration when designing the system is speed. Since the robots may have to react very quickly to stimuli in the environment, the reasoning in the AI must be as fast as possible. This is especially true in the hazardous environments for which this system could be useful for, as specified in \autoref{sec:intro}.

\subsection{Object Oriented Programming}
Another important design choice is to leverage object-oriented programming (OOP) as much as possible. OOP allows code to be very clean and reusable \cite{oop}. Principles such as polymorphism, encapsulation and abstraction will be followed closely. Indeed, the system should be as abstract as possible, while still performing its desired task. For instance, the system should be general enough to perform under simulations as well as in real-life environments. It should also ideally be able to perform in vastly different real-life environments, with varying tasks. Encapsulation can also be very useful, since each layer of the system has unique, localized functionality that does not need to be visible from the rest of the system.

The OOP principles of SOLID \cite{martin_2009} will also be followed:

\begin{description}
	\item[Single responsibility principle:] a class should only have a single responsibility. In particular, a class should only have one reason to change.
	
	\item[Open/closed principle:] a software entity's functionality can be extended without changing its source code.
	
	\item[Liskov substitution principle:] a class instance can be replaced by an instance of a subtype of that class while remaining correct.
	
	\item[Interface segregation principle:] a user of an interface should not be forced to depend on unnecessary methods. This encourages the use of multiple client-specific interfaces.
	
	\item[Dependency inversion principle:] high-level and low-level modules should depend on abstractions. In particular, a high-level module does not need to know the details of implementation of a low-level module and vice-versa.
\end{description}

\subsection{Readability and Documentation}
The code written should be very easy to understand. This means implementing each method and class in the most intuitive way possible and providing good documentation to support the code. This is to ensure that anyone wanting to work with the code or looking to understand how the system works has an easy time doing so.

\subsection{Testing}
An important criterion is that the code be heavily tested. This includes integration tests, covering end-to-end functionality, and unit tests, covering specific methods or classes. The unit tests should be behavior-driven, so that a developer reading the tests can easily understand the purpose of the element being tested.

\subsection{Quality Assurance}
With the numerous undergraduate students showing interest in working on Prometheus, there must be a system in place to ensure the quality of the code is upheld. This may include automatic testing of the code, as well as human review of code before being committed.

\section{Implementation}
\label{sec:implementation}

\subsection{Libraries}
Prometheus is a Java Maven project. This allows all the library dependencies to be specified in a \code{pom.xml} file in the root of the project directory. Maven allows dependencies to be easily added or removed in a Java project without needing to keep track of \code{jar} files.

An important library that was used is Google Guice. This is the backbone for all the dependencies in the code. Guice neatly allows the implementation of various important OOP principles, like dependency inversion. Notably, the \code{es} and \code{knn} packages have associated Guice modules which are used by the high-level Prometheus module. Guice factories were also created for classes which require special constructor arguments. A diagram of the various Guice dependencies in the project can be seen in \cref{fig:guice_graph} in \cref{sec:diagrams}.

The GraphStream library was also used for graph visualization and will be discussed in \cref{sec:impl_visualization}. The Apache Commons Lang library was used for standardized implementations of the \code{hashCode()}, \code{equals()}, \code{compareTo()} and \code{toString()} methods of Java objects. The very important TestNG and Mockito libraries were used for testing and will be discussed in \cref{sec:results}.

It is also important to note that Promtheus uses Java 8 because of the numerous improvements it introduced, including \code{Optional} objects and lambda expressions.

\subsection{Directory Structure}
Below is a description of the contents of each top-level directory in the project.

\begin{labeling}{\code{reports}}
	\item[\code{data}] Input data files for the KNN.
	\item[\code{docs}] Javadoc files.
	\item[\code{graphs}] Graphs created by the graphing tools.
	\item[\code{reports}] Reports on Prometheus.
	\item[\code{src}] Source code.
\end{labeling}

The \code{src} directory then contains the \code{main/java/} directory containing the main Prometheus code and the \code{test/java/} directory containing tests.

\subsection{Package Structure}
Within the main source code directory, the \code{prometheus}, \code{tags}, \code{nn}, \code{knn}, \code{es}, \code{meta} and \code{graphing} Java packages were created. Note that the \code{nn} and \code{meta} packages are simple skeletons of the NN and META layers. For most of these packages, sub-packages named \code{api}, \code{guice} and \code{internal} were created. Below is a description of the contents each of these packages should have.

\begin{labeling}{\code{internal}}
	\item[\code{api}] Public classes and interfaces. Only code relevant for a user of the package should be present here.
	\item[\code{guice}] Public Guice module. This module will be used by a user of the package and should install an internal Guice module.
	\item[\code{internal}] Internal classes and interfaces. Internal code that does not concern a user is found here, as well as an internal Guice module to install internal classes.
\end{labeling}

\subsection{Prometheus Interface}
A high-level \code{Prometheus} interface was created and was placed in the \code{prometheus} package. Its dependencies can be seen in \cref{fig:uml_prometheus}. The use of the \code{NeuralNetwork}, \code{KnowledgeNodeNetwork}, \code{ExpertSystem} and \code{MetaReasoner} interfaces is a good example of many of the SOLID principles, like single responsibility, interfaces segregation and dependency inversion. This interface allows a user to access the NN, KNN, ES and META layers via getter methods.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/uml_prometheus.pdf}
	\caption{UML diagram of the \code{Prometheus} dependencies.}
	\label{fig:uml_prometheus}
\end{figure}

\subsection{Tags}
As described in \autoref{sec:background}, the entire system revolves around tags passed from layer to layer. For this reason, careful thought was put into the design of these tags.

The tags need to be as general as possible. A natural choice for this structure would be a \code{String}, which would be relatively simple to pass around the system. However, these tags represent various concepts; each tag can either be a fact, a recommendation or a rule. If implemented as \code{String}s, the tags would have to be encoded on creation to represent each concept and decoded on use to retrieve the important information. This seems like a bad use of the OOP principles of Java. Furthermore, if specific functionality is needed in the future for each tag type, that can easily be implemented with a Java class.

For these reasons, the tags are implemented using an abstract \code{Tag} class, with \code{Predicate} and \code{Rule} subclasses. The \code{Predicate} abstract class is a superclass of the \code{Fact} and \code{Recommendation} classes, as shown in \cref{fig:uml_tags}. This is a good example of using the inheritance principle of OOP. The Liskov substitution principle was also kept in mind when designing these subclasses. The class strategy should also make manipulating the Tags faster, while incurring a slight memory overhead. To store these Tags in a database, they could be converted to JSON format using a library like Google Gson. On read from the database, they could easily be decoded using the same library. All these classes are present in the \code{tags} package of the code.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/uml_tags.pdf}
	\caption{UML diagram of the major classes in the \code{tags} package.}
	\label{fig:uml_tags}
\end{figure}

The \code{Tag} and \code{Predicate} classes themselves are abstract. This means that an object may not be directly instantiated as either, but must be instantiated as one of its subclasses. This makes sense, since a tag \emph{must} be one of the three types: rule, recommendation or fact. This is an example of using the abstraction principle of OOP.

The \code{Rule} class has the following important fields:

\begin{labeling}{\code{outputPredicates}}
	\item[\code{inputFacts}] \code{Set} of input \code{Facts}.
	\item[\code{outputPredicates}] \code{Set} of output \code{Predicates}.
\end{labeling}

The \code{Fact} and \code{Recommendation} classes have the following fields:

\begin{labeling}{\code{predicateName}}
	\item[\code{predicateName}] \code{String} representing the predicate name.
	\item[\code{arguments}] \code{List} of arguments to the predicate.
\end{labeling}

It is also very important that these tag objects be immutable by a user after creation, since they will be used as keys to map to KNs in the KNN, as will be discussed in the next section. To achieve this, the objects may have getter methods, but do not have any setter methods. In addition, if an object must return a collection like a \code{List}, it is made immutable to the user by methods such as \code{Collections.immutableList()}. The \code{Fact}, \code{Recommendation} and \code{Rule} classes were also made \code{final}, since it is not expected that these should be sub-classed. This is a good example of the open-closed principle.

\subsection{Knowledge Node Network}

All code relating directly to the KNN was placed in the \code{knn} package of the project. A UML diagram of the important classes in the \code{knn} package can be seen in \cref{fig:uml_knn}.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/uml_knn.pdf}
	\caption{UML diagram of the major classes in the \code{knn} package.}
	\label{fig:uml_knn}
\end{figure}

The KNN layer is based around the \code{KnowledgeNodeNetwork} interface. Its implementation, \code{KnowledgeNodeNetworkImpl}, has the following fields:

\begin{labeling}{\code{activeTags}}
	\item[\code{mapKN}] One-to-one \code{Map} of input \code{Tag}s to associated \code{KnowledgeNode}s.
	\item[\code{activeTags}] \code{HashSet} of active \code{Tag}s, corresponding to input \code{Tag}s of fired \code{KnowledgeNode}s.
\end{labeling}

The choice of \code{HashSet} for the \code{activeTags} field is not arbitrary. Indeed, \code{HashSets} were used for most of the collections with variable size in the ES and KNN. The original specifications mentioned using \code{ArrayLists}, but, since there is no specific iteration order necessary for most operations in the ES and KNN, these collections were changed to \code{HashSets}. \code{HashSets} are also faster because they have $O(1)$ access time, whereas \code{ArrayLists} have $O(N)$, where $N$ is the number of elements in the collection. Access time is important because the tags in the KNN and ES are accessed often. \code{HashSets} also have the advantage of only permitting unique elements. This is useful because there should never be two copies of the same tag or the same KN in the system.

The \code{KnowledgeNode} class implements the functionality of a KN, which has the following important fields to implement the functionality described in \autoref{sec:background}:

\begin{labeling}{\code{outputTags}}
	\item[\code{inputTag}] Input \code{Tag}.
	\item[\code{outputTags}] \code{HashSet} of output \code{Tags}.
	\item[\code{activation}] \code{int} starting at 0, incrementing when the \code{KnowledgeNode} is excited.
	\item[\code{threshold}] \code{int} threshold that causes firing of the \code{KnowledgeNode}.
	\item[\code{strength}] \code{int} that biases the activation of a \code{KnowledgeNode}, causing early firing.
	\item[\code{belief}] \code{int} representing the belief that the \code{inputTag} is true (0 to 1).
	\item[\code{age}] \code{long} representing the age of the \code{KnowledgeNode}.
\end{labeling}

\subsubsection{Excitation}

There are different ways that KN excitation could be implemented. With simple linear activation, excitation would increment the node's activation parameter, which initially starts at 0. If $activation \geq threshold$, the KN fires, causing the activation of the output tags. The activation can also be implemented using a sigmoid function, which is more representative of neurons in the brain \cite{neuro}. The linear activation was chosen to be implemented for its simplicity.

\subsubsection{Strength}

A simple implementation of strength would be as a constant coefficient multiplying the activation parameter. So, instead of checking when the activation is greater than the threshold, one would check if $activation \times strength \geq threshold$, where the strength is positive. The strength value could be 0 however, which effectively shuts off the KN. Another way of implementing strength is to check $activation + strength \geq threshold$. In this case, strength can be negative and make the KN fire later than normal. The constant coefficient version of strength was implemented.

\subsubsection{Search}

The most important methods in the \code{KnowledgeNodeNetwork} are the ones relating to searching and thinking, as described in \cref{sec:background}. The search methods are \code{directSearch()}, \code{forwardSearch()}, \code{backwardSearch()} and \code{lambdaSearch()}. The \code{directSearch()} method takes as input the \code{Tag} to activate and returns the \code{Set} of \code{Tag}s activated as a result of exciting the \code{KnowledgeNode} associated with the input \code{Tag}. Note that the input \code{Tag} itself is not returned.
Similarly, the other search methods take a \code{Set} of \code{Tag}s as input and return the \code{Set} of \code{Tag}s activated as a result of searching. The other search methods also take a \code{ply} parameter specifying the depth of the search. If \code{ply} is 0, the search continues until quiescence, i.e., until no \code{Tag}s are activated during a search cycle.

For each of the search methods, there is an associated searcher class, i.e., \code{DirectSearcher}, \code{ForwardSearcher}, \code{BackwardSearcher} and \code{LambdaSearcher}. This is a good example of the single responsibility principle. Delegating the search behavior to different classes allows for modularity and easy unit testing. Re-use of these classes was also taken advantage of, with \code{ForwardSearcher} using \code{DirectSearcher}, and \code{LambdaSearcher} using \code{ForwardSearcher} and \code{BackwardSearcher}, as shown in \cref{fig:uml_knn}. The \code{ForwardSearcher}, \code{BackwardSearcher} and \code{LambdaSearcher} also extend a \code{Searcher} abstract class, which handles some common functionality, i.e., searching until quiescence when the \code{ply} is 0.

Similarly, there are methods relating to thinking, i.e, \code{forwardThink()}, \code{backwardThink()} and \code{lambdaThink()}. These behave in the same way as their searching counterparts, except that they take as input all the currently active tags in the KNN, instead of user-provided input.

\subsubsection{Aging}

There are two main choices for the implementation of aging of the KNs:

\begin{enumerate}
	\item Increment an age counter (from 0) for every KN every $x$ amount of time. Once a KN is excited, its age is reset to 0. If the age exceeds a certain threshold, it is discarded. The KNs can be stored in a sorted mapping from the age counter to the KNs, where a KN is simply moved to the next slot when its age is updated.
	
	\item The KN's age is initialized to the current UNIX time. When a KN is about to be excited, the current UNIX time is compared to the last stored one. If the difference is greater than some threshold, the KN is discarded. Otherwise, the KN's age is set to the current UNIX time. The KNs can be stored in a sorted mapping from age to KN.
\end{enumerate}

The second method from the above was chosen for the main reason that it is computationally more efficient to update a KN upon exciting it, rather than updating multiple at a time every $x$ time interval. There is a trade-off however, since the first method has a simpler storage mechanism, dealing with either incrementing an index or resetting an index to 0 at every age update. The second method has to instead keep a sorted mapping from the UNIX time to the KNs. While this is more complex, it can be relatively simply implemented with a \code{TreeSet} in Java, which is what was chosen. In this way, for each search method, the youngest KNs are excited first.

To accomplish this, a new \code{TreeSet} field was created in the KNN named \code{ageSortedKNs}. This is a set of KNs sorted by their age. It is used in backward search to iterate over the KNs, and in direct search to update the age. There is also an associated age limit in the backward searcher named \code{backwardSearchAgeLimit} which can be set by the user. While iterating over the KNs, if any KN's age is greater than this threshold, the current ply's search terminates.

\subsection{Expert System}

All code relating directly to the ES was placed in the \code{es} package of the project. A UML diagram of the \code{es} package can be seen in \cref{fig:uml_es}.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/uml_es.pdf}
	\caption{UML diagram of the major classes in the \code{es} package.}
	\label{fig:uml_es}
\end{figure}

The ES layer is based around the \code{ExpertSystem} interface. Its implementation, \code{ExpertSystemImpl}, has the following important fields:

\begin{labeling}{\code{recommendations}}
	\item[\code{readyRules}] \code{HashSet} of \code{Rules} that have not been activated yet.
	\item[\code{activeRules}] \code{HashSet} of active \code{Rules}.
	\item[\code{facts}] \code{HashSet} of active \code{Facts}.
	\item[\code{recommendations}] \code{HashSet} of active \code{Recommendations}.
\end{labeling}

The most important method in the \code{ExpertSystem} is \code{think()}, which implements the functionality described in \cref{sec:background}. It has the following parameters:

\begin{labeling}{\code{generateRule}}
	\item[\code{ply}] The amount of thinking cycles to execute.
	\item[\code{generateRule}] If \code{true}, generates a \code{Rule} based on the active \code{Fact}s and the ones activated as a result of thinking.
\end{labeling}

The \code{think()} method has an associated \code{Thinker} class, whose sole purpose is to execute thinking cycles by using the \code{ThinkCycleExecutor} class. It does so by iterating over the ready rules in the ES and and activating those whose input facts are active.

The \code{rest()} method allows the creation of new rules based on existing ones, with the associated \code{Rester} class, which in turn uses the \code{RuleMerger} classes. It merges rules when one rule implies another. For example, if we have $P(A) \rightarrow P(B)$ and $P(B) \rightarrow P(C)$, then a new rule can be created: $P(A) \rightarrow P(C)$.

The \code{teach()} method parses simple \emph{if-then} sentence \code{String}s to generate rules by using the \code{Teacher} class. For example, the sentence \emph{if} $P(A)$ \emph{then} $P(B)$ would be converted to a rule of the form $P(A) \rightarrow P(B)$. The currently supported words denoting rule input are \emph{if}, \emph{when}, \emph{while} and \emph{first}. The words denoting rule output are \emph{then}, \emph{next} and \emph{do}.

\subsection{Visualization} \label{sec:impl_visualization}
The Java graph visualization library GraphStream was used to visualize the KNN and the process of searching or thinking through it. The graphing code created was placed in the \code{graphing} package. A UML diagram of the important graphing dependencies can be seen in \cref{fig:uml_graphing}. A legend for reading the produced graph can be seen in \cref{fig:knn_graph_legend}. The small nodes represent tags and the bigger nodes represent KNs. The red nodes indicate either active tags or fired KNs. Non-fired KNs are blue. Facts are purple, rules are teal and recommendations are orange. The visual tests for this graphing tool were placed in the test directory and will be discussed in \cref{sec:results}.

\begin{figure}[!htb]
	\includegraphics[width=\columnwidth]{figures/uml_graphing.pdf}
	\caption{UML diagram of the important classes in the \code{graphing} package.}
	\label{fig:uml_graphing}
\end{figure}

\begin{figure*}[!htb]
	\includegraphics[width=\textwidth]{figures/knn_graph_legend.pdf}
	\caption{Legend for reading the graph produced by \code{KnnGraphVisualizer}.}
	\label{fig:knn_graph_legend}
\end{figure*}

\subsection{Documentation}
Extensive documentation was created as comments in the code and converted to Javadoc. This can be found in the \code{docs} directory of the project, or hosted online\footnote{The Javadoc can be found here:\\ \url{http://seanstappas.me/prometheus-ai/}}. Instructions are also provided in the README located in the top-level directory of the project.

\begin{table*}[!htb]
	\large
	\centering
	\caption[Test setup for \code{testES()}.]
	{Test setup for \code{testES()}. Middle activation steps omitted.}
	\begin{tabular}{c | c | c | c | c} 
		\textbf{State} & \textbf{Ready Rules} & \textbf{Active Rules} & \specialcell{\textbf{Active} \\ \textbf{Facts}} & \specialcell{\textbf{Active} \\ \textbf{Recommendations}}  \\ \hline
		
		Initial & \specialcell{$A, B\rightarrow D$ \\ $D, B\rightarrow E$ \\ $D, E\rightarrow F$\\ $G, A\rightarrow H$ \\ $E, F\rightarrow @Z$} &  & $A, B$ & $@X, @Y$ \\ \hline
		
		$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\ \hline
		
		Final & $G, A\rightarrow H$ & \specialcell{$A, B\rightarrow D$ \\ $D, B\rightarrow E$ \\ $D, E\rightarrow F$ \\ $E, F\rightarrow @Z$} & \specialcell{$A, B$ \\ $D, E,$ \\ $F$} & $@X, @Y, @Z$		
	\end{tabular}
	\label{testES}
\end{table*}

\section{Results and Tests} \label{sec:results}
Unit and integration tests in Prometheus were conducted using the TestNG framework in Java, which provides a simple and intuitive way to create assertions in tests. Some visual tests using the KNN graphing tool were also created. All tests were placed in the test directory of the project.

\subsection{Unit Tests}
Unit tests for individual methods and classes were constructed using TestNG and Mockito. Mockito allows easy mocking of dependencies. These tests were created in parallel with writing the functional code, to ensure proper functionality. 

The unit tests are behavior-driven and written in such a way that someone reading them can easily understand the intended behavior of the element under test. The test methods follow the \code{mustAction()} naming convention. For example, the \code{RuleMergerTest} class has a \code{mustMakeEmptyRule()} method, which tests that the merger returns an empty \code{Optional} object when there are no rules to merge.

The body of each unit test method has three sections: \emph{given}, \emph{when} and \emph{then}. The \emph{given} section sets up the intended return values of the dependencies mocked by Mockito, if present. The \emph{when} section executes the actual method under test. The \emph{then} section contains the TestNG assertions concerning the result of executing the method under test.

The package location of each unit test mirrors the location of the class under test in the main code. For example, the \code{BackwardSearcher.java} file is located in \code{src/main/java/knn/internal/} and its unit test, \code{BackwardSearcherTest.java}, is therefore located in \code{src/test/java/knn/internal/}. This allows the unit tests to access package-private classes and methods.

\subsection{Integration Tests}
Integration tests were also created to test end-to-end behavior. These are more high-level than unit tests and simply test input and output of methods without mocking their dependencies. All integration tests are located in \code{src/test/java/integration/}. Tests for the ES, KNN and both combined can be found here.

For example, the test setup for an ES integration test can be seen in \autoref{testES}. The columns from left to right (ignoring \emph{State}) correspond to the elements in \code{readyRules}, \code{activeRules}, \code{facts} and \code{recommendations}, respectively. The first row corresponds to the initial state of the ES and the last row corresponds to the expected final state. The presence of both the initial and final states are asserted with TestNG. This test can be found in the \code{SimpleExpertSystemTest} class.

\subsection{Visual Tests}
Some visual tests were carried out with the created KNN visualization tool. These can be found in \code{src/test/java/graphing/}. Visualizations of forward, backward and lambda search can be seen in \cref{fig:forward_search_test,fig:backward_search_test,fig:lambda_search_test}. These tests can be found in \code{KnnSimpleForwardThinkVisualizer.java}, \code{KnnSimpleBackwardThinkVisualizer.java} and \code{KnnSimpleLambdaThinkVisualizer.java}. Refer to \cref{fig:knn_graph_legend} for the meaning of the node colors. In these tests, a threshold of 1 was used for simplicity and the initial active tags are provided as search input.

\subsection{Quality Assurance}
All the unit tests and integration tests are run in the continuous integration suite provided by Travis CI\footnote{The Travis CI builds can be found here:\\ \url{https://travis-ci.com/seanstappas/prometheus-ai} \\} on the GitHub repository\footnote{The GitHub repository can be found here:\\ \url{https://github.com/seanstappas/prometheus-ai/}}. This enforces a level of quality for the code when someone pushes a change.

The Travis CI builds also ensure that are the dependencies are loaded properly and that some standard code quality checks are passed. These include \code{FindBugs} for finding bugs in the code, \code{checkstyle} for enforcing a code style and \code{jacoco} for enforcing \SI{90}{\percent} code coverage with tests. The \code{checkstyle} configuration is inspired from the Java Sun style and can be found in the \code{checkstyle.xml} file in the root of the project.

\begin{figure*}
	\begin{subfigure}[!htb]{0.32\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_forward_think_0.pdf}
		\caption{Iteration 0.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.32\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_forward_think_1.pdf}
		\caption{Iteration 1.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.32\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_forward_think_2.pdf}
		\caption{Iteration 2.}
	\end{subfigure}
	\caption{Forward search visualization in the KNN.}
	\label{fig:forward_search_test}
\end{figure*}

\begin{figure*}[!htb]
	\centering
	\begin{subfigure}[!htb]{0.32\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_backward_think_0.pdf}
		\caption{Iteration 0.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.32\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_backward_think_1.pdf}
		\caption{Iteration 1.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.32\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_backward_think_2.pdf}
		\caption{Iteration 2.}
	\end{subfigure}
	\caption{Backward search visualization in the KNN.}
	\label{fig:backward_search_test}
\end{figure*}


\begin{figure*}[!htb]
	\centering
	\begin{subfigure}[!htb]{0.19\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_lambda_think_0.pdf}
		\caption{Iteration 0.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.19\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_lambda_think_1.pdf}
		\caption{Iteration 1.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.19\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_lambda_think_2.pdf}
		\caption{Iteration 2.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.19\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_lambda_think_3.pdf}
		\caption{Iteration 3.}
	\end{subfigure}
	\begin{subfigure}[!htb]{0.19\textwidth}
		\centering
		\includegraphics[width=\columnwidth]{figures/knn_simple_lambda_think_4.pdf}
		\caption{Iteration 4.}
	\end{subfigure}
	\caption{Lambda search visualization in the KNN.}
	\label{fig:lambda_search_test}
\end{figure*} 

\section{Impact on Society and the Environment}
\label{sec:impact}
% In one or two pages, discuss the environmental and/or social impact of your project. Your analysis should include your work at McGill as part of this project, however, the main focus should be on the product/system you are designing (e.g., the cost/benefit/risk of manufacturing it, the cost/benefit/risk for consumers using it) or the problem your thesis is addressing (e.g., how will solving the problem influence/affect/benefit society and the environment). Particular emphasis should be given to:


\subsection{Use of Non-renewable Resources}
% Consider all stages of the product from design, manufacturing, distribution, use by consumers, and disposal/recycling.

As purely a software project, there are no physical materials needed to construct this system. For this reason, less emphasis will be put on this section. The only related physical resources potentially needed are the materials needed to construct the robots and the computers to house the software. One area of concern could be the energy source of the robots themselves, which would probably vary depending on context. Ideally, the source should be a renewable one. For example, solar panels could be placed on the robots to provide energy.

\subsection{Environmental Benefits}
% Benefits to the environment, comparisons with more polluting technologies etc.

Prometheus could be used in a context beneficial to the environment. For example, the system could be used as a tool to control robots after oil spills, where the robots could theoretically safely contain the problem faster than humans and thus limit the risk on the environment. There is already research being done on employing robots in this context. Indeed, MIT's Senseable City Lab has been working on Seaswarm, a system composed of a fleet of vehicles to help clean future oil spills \cite{seaswarm}. An AI like Prometheus to control a swarm of robots like this could be very valuable. 

\subsection{Safety and Risk}
% To you undertaking the project, as well as to any potential users of the solution once it is finished.

It is critical that, once this system is completed, it is used in an ethical way and for the right purposes. One example of use that may cause ethical concern is in a military setting, where an AI system like the one described here could be used in a battlefield in place of soldiers. Indeed, the US Department of Defense has plans to employ AI for autonomous weapons to attack targets without human intervention in the future \cite{military}. This would have the advantage of potentially saving human soldiers' lives \cite{define_military_ai}. However, there are also concerns because this would make it much easier to start a battle. More than 3000 AI and robotics researchers have signed an open letter arguing against a military AI arms race \cite{openletter}. They argue that autonomous weapons would not be beneficial to society, since they would be ideal for assassinations, destabilizing countries or selectively subduing or killing a population.

Another possible issue is the future loss of jobs to be done by humans, with automated systems like Prometheus replacing physical labour. This problem can be solved as a society, perhaps by having more support for universal basic income (UBI). Telsa CEO Elon Musk is a proponent of the idea, saying that UBI will be necessary in the future \cite{musk}. Microsoft co-founder Bill Gates suggests possibly having a tax on robots to help pay for this income \cite{gates}.

In the very long term, there are concerns with the possibility that an AI system might achieve intelligence and awareness close to a human. If such an AI were to obtain ``consciousness'' in its own way, should that entity be entitled to its own rights, like humans or animals are? The issue has been mentioned by the Institute for the Future, calling for the possibility of ``robo-rights'' in the future \cite{robo_rights}.


\subsection{Benefits to Society}
% Quality of life, economic benefits, etc.

This type of system could be extremely useful in many contexts in society. For instance, the system could be used to send and control robots in an area that would otherwise be very dangerous for humans. For example, robots are often used in the aftermath of nuclear disasters to prevent the unnecessary loss of human life. Indeed, in the Chernobyl nuclear disaster, the Soviet authorities employed the use of robots to avoid losses of human life \cite{chernobyl}. With an AI like Prometheus, the robots could be controlled in an intelligent manner.

The system could also be used to further space exploration, with an AI controlling multiple robots exploring the surface of Mars, for instance. The value of AI in this context has been clearly shown, with the Mars Curiosity rover recently being upgraded to have its own AI system using computer vision to identify rocks \cite{rover}. This system can therefore help further important cutting-edge research in space exploration.

\section{Conclusion}
% Use this section to summarize what was accomplished in this semester, provide a summary of the next steps and share any insight you have learned.

The Expert System (ES) and Knowledge Node Network (KNN) layers of the Prometheus AI model were completed in Java based on design criteria and feedback from the supervisor. These layers were tested using the TestNG Java framework with positive results and extensive Javadoc was produced. Possible impacts on the environment and society were also discussed.

Possible future work would include finalizing the entire system by building the Neural Network (NN) and Meta Reasoner (META) layers. It would also include implementing more complex features, such as attention and learning in the KNN.

\clearpage
\onecolumn

\bibliography{readings}{}
\bibliographystyle{IEEEtran}

\appendix
\renewcommand\thefigure{\thesection.\arabic{figure}}
\setcounter{figure}{0}

\clearpage
%\begin{landscape}   
	\section{Diagrams}
	\label{sec:diagrams}
	\begin{figure}[!htb]
		\includegraphics[width=\columnwidth]{figures/guice_graph.pdf}
		\caption{Guice dependency graph.}
		\label{fig:guice_graph}
	\end{figure}
%\end{landscape}

\end{document}